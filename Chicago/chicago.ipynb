{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import concurrent.futures\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrapable:\n",
    "    def __init__(self, gender, year, url):\n",
    "        self.gender = gender\n",
    "        self.year = year\n",
    "        self.url = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_reader(url):\n",
    "    client = urlopen(url)\n",
    "    page = client.read()\n",
    "    page\n",
    "    client.close()\n",
    "\n",
    "    #open the result with BS\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a page of marathon finishers, adding the results to the master list\n",
    "def parse_page(scrapable):\n",
    "    url = scrapable.url\n",
    "    \n",
    "    print(f\"Current Page: {url}\\n\")\n",
    "    soup = soup_reader(url)\n",
    "\n",
    "    page_finishers = soup.find(\"ul\", \"list-group list-group-multicolumn\").find_all(\"li\", \"row\")\n",
    "\n",
    "    resultList = []\n",
    "\n",
    "    for finisher in page_finishers:\n",
    "\n",
    "        #skip the header row\n",
    "        if 'list-group-header' in finisher.attrs['class']:\n",
    "            continue\n",
    "\n",
    "        place_overall_search = finisher.find(\"div\", \"place-secondary\")\n",
    "        if place_overall_search is not None:\n",
    "            place_overall = place_overall_search.get_text()\n",
    "\n",
    "        #skip non-finishers\n",
    "        if place_overall is None or place_overall == 'â€“':\n",
    "            continue\n",
    "\n",
    "\n",
    "        place_gender_search = finisher.find(\"div\", \"place-primary\")\n",
    "        if place_gender_search is not None:\n",
    "            place_gender = place_gender_search.get_text()\n",
    "\n",
    "        runner_name = finisher.find(\"h4\", \"type-fullname\")\n",
    "        if runner_name is not None:\n",
    "            runner_name = runner_name.get_text()\n",
    "        #TODO: extract country\n",
    "        city_state = finisher.find(\"div\", \"list-field type-eval\").contents[1]\n",
    "\n",
    "        bib_number = finisher.find(\"div\", \"type-field\").contents[1]\n",
    "\n",
    "        division = finisher.find(\"div\", \"type-age_class\").contents[1]\n",
    "\n",
    "        times = finisher.find_all(\"div\", \"list-field type-time\")\n",
    "        half_time = times[0].contents[1]\n",
    "        full_time = times[1].contents[1]\n",
    "\n",
    "        result = {\n",
    "            \"place_overall\" : place_overall,\n",
    "            \"place_gender\" : place_gender,\n",
    "            \"runner_name\" : runner_name,\n",
    "            \"city_state\" : city_state,\n",
    "            \"bib_number\" : bib_number,\n",
    "            \"division\" : division,\n",
    "            \"time_half\" : half_time,\n",
    "            \"time_full\" : full_time,\n",
    "            \"gender\" : scrapable.gender,\n",
    "            \"year\" : scrapable.year\n",
    "        }\n",
    "\n",
    "        masterResults.append(result)\n",
    "\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pagination_limit(url):\n",
    "    soup = soup_reader(url)\n",
    "    \n",
    "    #Get the pagination object\n",
    "    pagination = soup.find(\"ul\", \"pagination\").find_all(\"li\")\n",
    "    \n",
    "    #The second to last item in the pagination object displays the final page number, that's what we want\n",
    "    li_length = len(pagination)\n",
    "    num_pages = int(pagination[li_length - 2].get_text())\n",
    "    \n",
    "    return num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls(event_code, year):\n",
    "    #find the number of pages of Male finisher results\n",
    "    male_pages = find_pagination_limit(f\"https://chicago-history.r.mikatiming.com/2015/?page=1&event={event_code}&lang=EN_CAP&num_results=1000&pid=search&pidp=start&search%5Bage_class%5D=%25&search%5Bsex%5D=M&search%5Bnation%5D=%25&search_sort=name\")\n",
    "    print(f\"Number of male pages: {male_pages}\")\n",
    "    \n",
    "    #find the number of pages of Female finisher results\n",
    "    female_pages = find_pagination_limit(f\"https://chicago-history.r.mikatiming.com/2015/?page=1&event={event_code}&lang=EN_CAP&num_results=1000&pid=search&pidp=start&search%5Bage_class%5D=%25&search%5Bsex%5D=W&search%5Bnation%5D=%25&search_sort=name\")\n",
    "    print(f\"Number of female pages: {female_pages}\")\n",
    "    \n",
    "    for i in range(1, male_pages+1):\n",
    "        s = Scrapable('Male', year, f\"https://chicago-history.r.mikatiming.com/2015/?page={i}&event={event_code}&lang=EN_CAP&num_results=1000&pid=search&pidp=start&search%5Bage_class%5D=%25&search%5Bsex%5D=M&search%5Bnation%5D=%25&search_sort=name\")\n",
    "        to_scrape.append(s)\n",
    "        \n",
    "    for i in range(1, female_pages+1):\n",
    "        s = Scrapable('Female', year, f\"https://chicago-history.r.mikatiming.com/2015/?page={i}&event={event_code}&lang=EN_CAP&num_results=1000&pid=search&pidp=start&search%5Bage_class%5D=%25&search%5Bsex%5D=W&search%5Bnation%5D=%25&search_sort=name\")\n",
    "        to_scrape.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_and_save():\n",
    "    df_results = pd.DataFrame(masterResults)\n",
    "    \n",
    "    #add the event name\n",
    "    df_results['Race'] = 'Chicago'\n",
    "    \n",
    "    #sort by finisher name for easier comparison to online results page\n",
    "    df_results.sort_values(by=['runner_name'], inplace=True)\n",
    "    \n",
    "    #save to csv\n",
    "    df_results.to_csv(f'Chicago.csv', index=False)\n",
    "    print(f\"Scraping complete.  Gathered {df_results.shape[0]} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = list()\n",
    "masterResults = [];\n",
    "\n",
    "events_to_scrape = {\n",
    "    '2000' : \"\",\n",
    "    '2001' : \"MAR_9999990E9A9236000000006A\",\n",
    "    '2002' : \"\",\n",
    "    '2003' : \"\",\n",
    "    '2004' : \"\",\n",
    "    '2005' : \"\",\n",
    "    '2006' : \"\",\n",
    "    '2007' : \"\",\n",
    "    '2008' : \"\",\n",
    "    '2009' : \"\",\n",
    "    '2010' : \"\",\n",
    "    '2011' : \"\",\n",
    "    '2012' : \"\",\n",
    "    '2013' : \"\",\n",
    "    '2014' : \"\",\n",
    "    '2015' : \"\",\n",
    "    '2016' : \"\",\n",
    "    '2017' : \"\",\n",
    "    '2018' : \"\",\n",
    "    '2019' : \"\",\n",
    "}\n",
    "\n",
    "for year,event_code in events_to_scrape.items():\n",
    "    generate_urls(event_code, year)\n",
    "\n",
    "#Use multithreading to speed up the scraping process significantly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "    executor.map(parse_page, to_scrape)\n",
    "cleanup_and_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
